Using TensorFlow backend.
[94mObteniendo datos...[0m
[93m[AVISO] 	Usuarios: 26449[0m
[93m[AVISO] 	Restaurantes: 716[0m
[93m[AVISO] Cargando datos generados previamente...[0m
[94mCreando modelo...[0m


##################################################
 MODELV6
##################################################
 modelv60 BÃ¡sico
##################################################
[93m[AVISO] Existen 4 combinaciones posibles[0m
--------------------------------------------------
de8827fc38f37da53c62d373ae689123
--------------------------------------------------
[1mlearning_rate: [0m5e-05
[1mdropout: [0m1.0
--------------------------------------------------
E	E_TIME	LDECAY	T_LOSS
0	12.323	 1.001	 0.698
1	11.693	 0.991	 0.540
2	11.736	 0.980	 0.437
3	 9.881	 0.969	 0.367
4	11.215	 0.957	 0.343
5	11.119	 0.945	 0.306
6	11.729	 0.933	 0.304
7	10.913	 0.920	 0.330
8	11.027	 0.907	 0.284
9	11.159	 0.893	 0.282
10	11.161	 0.879	 0.356
11	11.734	 0.865	 0.263
12	11.050	 0.850	 0.256
13	11.003	 0.835	 0.274
14	10.914	 0.820	 0.246
15	10.336	 0.805	 0.255
16	11.167	 0.789	 0.248
17	10.769	 0.773	 0.241
18	11.105	 0.757	 0.248
19	11.003	 0.741	 0.264
20	11.277	 0.725	 0.259
21	11.677	 0.708	 0.239
22	11.706	 0.692	 0.233
23	11.673	 0.675	 0.278
24	10.515	 0.658	 0.249
25	11.636	 0.641	 0.236
26	11.067	 0.624	 0.239
27	11.219	 0.607	 0.250
28	11.166	 0.590	 0.239
29	11.054	 0.574	 0.228
30	10.815	 0.557	 0.239
31	11.362	 0.540	 0.232
32	11.152	 0.523	 0.232
33	10.911	 0.507	 0.232
34	11.228	 0.490	 0.256
35	11.120	 0.474	 0.224
36	11.136	 0.457	 0.229
37	11.311	 0.441	 0.228
38	11.418	 0.425	 0.222
39	10.931	 0.409	 0.215
40	11.148	 0.394	 0.206
41	11.662	 0.378	 0.204
42	11.668	 0.363	 0.235
43	11.332	 0.348	 0.221
44	11.043	 0.333	 0.214
45	10.799	 0.319	 0.211
46	11.553	 0.305	 0.210
47	11.150	 0.291	 0.209
48	11.081	 0.277	 0.209
49	10.771	 0.264	 0.207
50	11.097	 0.251	 0.206
51	11.402	 0.238	 0.202
52	10.619	 0.226	 0.200
53	11.130	 0.214	 0.201
54	11.308	 0.202	 0.196
55	11.113	 0.191	 0.187
56	10.976	 0.180	 0.180
57	11.532	 0.169	 0.178
58	10.935	 0.159	 0.177
59	11.453	 0.149	 0.176
60	11.641	 0.139	 0.178
61	10.929	 0.130	 0.176
62	11.426	 0.121	 0.173
63	11.753	 0.113	 0.173
64	10.930	 0.104	 0.172
65	10.878	 0.097	 0.171
66	10.922	 0.089	 0.170
67	10.792	 0.082	 0.170
68	11.072	 0.075	 0.169
69	11.476	 0.069	 0.169
70	11.378	 0.063	 0.168
71	11.295	 0.057	 0.168
72	11.435	 0.052	 0.168
73	10.899	 0.047	 0.167
74	11.076	 0.042	 0.167
75	11.522	 0.038	 0.166
76	11.010	 0.034	 0.166
77	11.319	 0.030	 0.166
78	11.219	 0.026	 0.166
79	11.374	 0.023	 0.165
80	11.404	 0.020	 0.165
81	10.698	 0.017	 0.165
82	10.559	 0.015	 0.165
83	10.369	 0.013	 0.165
84	11.091	 0.011	 0.165
85	11.241	 0.009	 0.165
86	10.860	 0.008	 0.165
87	11.078	 0.006	 0.165
88	11.531	 0.005	 0.164
89	11.313	 0.004	 0.164
90	11.324	 0.003	 0.164
91	11.290	 0.003	 0.164
92	11.302	 0.002	 0.164
93	10.985	 0.002	 0.164
94	11.599	 0.002	 0.164
95	10.930	 0.001	 0.164
96	11.561	 0.001	 0.164
97	11.014	 0.001	 0.164
98	 9.861	 0.001	 0.164
99	13.741	 0.001	 0.164	 0.368	 0.318
--------------------------------------------------
05d6678161b506641204228585f7bcc8
--------------------------------------------------
[1mlearning_rate: [0m1e-05
[1mdropout: [0m1.0
--------------------------------------------------
E	E_TIME	LDECAY	T_LOSS
0	11.684	 1.001	 0.811
1	10.820	 0.991	 0.709
2	10.689	 0.980	 0.673
3	11.496	 0.969	 0.644
4	10.381	 0.957	 0.615
5	11.178	 0.945	 0.586
6	10.161	 0.933	 0.554
7	11.309	 0.920	 0.522
8	11.038	 0.907	 0.489
9	11.068	 0.893	 0.460
10	11.419	 0.879	 0.435
11	11.004	 0.865	 0.412
12	10.596	 0.850	 0.391
13	11.229	 0.835	 0.373
14	11.473	 0.820	 0.358
15	11.363	 0.805	 0.344
16	10.389	 0.789	 0.332
17	10.219	 0.773	 0.321
18	10.628	 0.757	 0.311
19	11.248	 0.741	 0.302
20	11.025	 0.725	 0.294
21	11.050	 0.708	 0.287
22	10.357	 0.692	 0.280
23	11.235	 0.675	 0.275
24	10.634	 0.658	 0.269
25	11.439	 0.641	 0.264
26	10.919	 0.624	 0.260
27	10.804	 0.607	 0.256
28	10.936	 0.590	 0.252
29	11.312	 0.574	 0.251
30	11.021	 0.557	 0.247
31	11.464	 0.540	 0.244
32	11.750	 0.523	 0.242
33	11.512	 0.507	 0.239
34	10.839	 0.490	 0.236
35	11.273	 0.474	 0.234
36	10.779	 0.457	 0.232
37	10.752	 0.441	 0.230
38	10.850	 0.425	 0.227
39	11.425	 0.409	 0.225
40	10.552	 0.394	 0.223
41	10.556	 0.378	 0.222
42	10.654	 0.363	 0.220
43	11.053	 0.348	 0.218
44	10.233	 0.333	 0.217
45	10.251	 0.319	 0.215
46	10.329	 0.305	 0.214
47	10.521	 0.291	 0.212
48	10.123	 0.277	 0.211
49	10.255	 0.264	 0.210
50	10.241	 0.251	 0.209
51	10.230	 0.238	 0.208
52	10.170	 0.226	 0.207
53	11.241	 0.214	 0.206
54	10.758	 0.202	 0.205
55	11.439	 0.191	 0.205
56	11.454	 0.180	 0.204
57	11.035	 0.169	 0.203
58	10.669	 0.159	 0.203
59	10.867	 0.149	 0.202
60	10.797	 0.139	 0.201
61	11.354	 0.130	 0.201
62	11.046	 0.121	 0.200
63	11.403	 0.113	 0.200
64	10.068	 0.104	 0.200
65	10.593	 0.097	 0.199
66	11.278	 0.089	 0.199
67	11.166	 0.082	 0.198
68	11.024	 0.075	 0.198
69	10.997	 0.069	 0.198
70	10.804	 0.063	 0.198
71	 9.679	 0.057	 0.197
72	10.576	 0.052	 0.197
73	10.726	 0.047	 0.197
74	10.328	 0.042	 0.197
75	10.688	 0.038	 0.197
76	11.142	 0.034	 0.197
77	11.107	 0.030	 0.196
78	10.717	 0.026	 0.196
79	10.166	 0.023	 0.196
80	10.298	 0.020	 0.196
81	10.220	 0.017	 0.196
82	10.706	 0.015	 0.196
83	11.403	 0.013	 0.196
84	11.028	 0.011	 0.196
85	10.570	 0.009	 0.196
86	11.157	 0.008	 0.196
87	10.803	 0.006	 0.196
88	11.196	 0.005	 0.196
89	10.747	 0.004	 0.196
90	10.984	 0.003	 0.196
91	11.268	 0.003	 0.196
92	11.328	 0.002	 0.196
93	10.498	 0.002	 0.196
94	10.859	 0.002	 0.196
95	11.011	 0.001	 0.196
96	11.575	 0.001	 0.196
97	10.781	 0.001	 0.196
98	11.521	 0.001	 0.196
99	13.342	 0.001	 0.196	 0.365	 0.307
--------------------------------------------------
a6033a2f7d8e5d7a9e178da5803e2e92
--------------------------------------------------
[1mlearning_rate: [0m5e-06
[1mdropout: [0m1.0
--------------------------------------------------
E	E_TIME	LDECAY	T_LOSS
0	11.544	 1.001	 0.895
1	10.603	 0.991	 0.753
2	11.487	 0.980	 0.720
3	10.924	 0.969	 0.697
4	10.862	 0.957	 0.679
5	11.059	 0.945	 0.661
6	10.953	 0.933	 0.645
7	11.402	 0.920	 0.628
8	10.176	 0.907	 0.611
9	10.976	 0.893	 0.594
10	10.814	 0.879	 0.576
11	10.927	 0.865	 0.558
12	11.037	 0.850	 0.542
13	10.372	 0.835	 0.525
14	10.826	 0.820	 0.510
15	10.610	 0.805	 0.494
16	11.016	 0.789	 0.480
17	11.321	 0.773	 0.467
18	11.065	 0.757	 0.454
19	11.210	 0.741	 0.443
20	10.759	 0.725	 0.432
21	11.088	 0.708	 0.422
22	10.891	 0.692	 0.413
23	10.754	 0.675	 0.405
24	11.171	 0.658	 0.396
25	10.708	 0.641	 0.388
26	11.293	 0.624	 0.381
27	10.610	 0.607	 0.374
28	10.969	 0.590	 0.368
29	10.499	 0.574	 0.362
30	11.248	 0.557	 0.356
31	11.249	 0.540	 0.351
32	10.869	 0.523	 0.346
33	10.884	 0.507	 0.342
34	11.393	 0.490	 0.337
35	10.579	 0.474	 0.333
36	10.933	 0.457	 0.330
37	11.034	 0.441	 0.326
38	11.448	 0.425	 0.323
39	11.146	 0.409	 0.320
40	11.180	 0.394	 0.317
41	10.741	 0.378	 0.315
42	11.067	 0.363	 0.312
43	10.766	 0.348	 0.310
44	11.212	 0.333	 0.308
45	11.502	 0.319	 0.306
46	10.664	 0.305	 0.304
47	11.254	 0.291	 0.302
48	11.257	 0.277	 0.300
49	11.740	 0.264	 0.298
50	10.566	 0.251	 0.297
51	11.242	 0.238	 0.295
52	10.186	 0.226	 0.294
53	10.228	 0.214	 0.293
54	10.529	 0.202	 0.291
55	11.043	 0.191	 0.290
56	10.668	 0.180	 0.289
57	10.931	 0.169	 0.288
58	10.955	 0.159	 0.287
59	11.245	 0.149	 0.286
60	10.850	 0.139	 0.286
61	10.446	 0.130	 0.285
62	10.862	 0.121	 0.284
63	11.081	 0.113	 0.283
64	10.773	 0.104	 0.283
65	11.122	 0.097	 0.282
66	11.057	 0.089	 0.282
67	10.984	 0.082	 0.281
68	10.825	 0.075	 0.281
69	11.263	 0.069	 0.281
70	10.446	 0.063	 0.280
71	10.586	 0.057	 0.280
72	11.652	 0.052	 0.280
73	11.484	 0.047	 0.279
74	11.112	 0.042	 0.279
75	10.900	 0.038	 0.279
76	11.422	 0.034	 0.279
77	11.180	 0.030	 0.279
78	10.910	 0.026	 0.278
79	11.163	 0.023	 0.278
80	11.018	 0.020	 0.278
81	11.640	 0.017	 0.278
82	11.005	 0.015	 0.278
83	11.264	 0.013	 0.278
84	10.959	 0.011	 0.278
85	11.427	 0.009	 0.278
86	10.984	 0.008	 0.278
87	10.932	 0.006	 0.278
88	10.723	 0.005	 0.278
89	11.233	 0.004	 0.278
90	10.599	 0.003	 0.278
91	10.342	 0.003	 0.278
92	10.684	 0.002	 0.278
93	11.402	 0.002	 0.278
94	10.249	 0.002	 0.278
95	11.000	 0.001	 0.278
96	10.583	 0.001	 0.278
97	10.569	 0.001	 0.278
98	11.274	 0.001	 0.278
99	13.914	 0.001	 0.277	 0.375	 0.333
--------------------------------------------------
62c839373eb341abe43dfd0a670969fb
--------------------------------------------------
[1mlearning_rate: [0m1e-06
[1mdropout: [0m1.0
--------------------------------------------------
E	E_TIME	LDECAY	T_LOSS
0	11.522	 1.001	 1.316
1	10.660	 0.991	 0.823
2	11.148	 0.980	 0.804
3	11.446	 0.969	 0.791
4	10.519	 0.957	 0.780
5	10.630	 0.945	 0.769
6	10.907	 0.933	 0.759
7	11.082	 0.920	 0.749
8	11.332	 0.907	 0.740
9	11.021	 0.893	 0.731
10	11.053	 0.879	 0.723
11	11.201	 0.865	 0.716
12	11.060	 0.850	 0.710
13	10.851	 0.835	 0.705
14	10.991	 0.820	 0.699
15	10.534	 0.805	 0.695
16	10.489	 0.789	 0.691
17	11.119	 0.773	 0.686
18	11.206	 0.757	 0.682
19	10.537	 0.741	 0.678
